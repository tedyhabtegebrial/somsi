<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}

	h1 {
		font-size:32px;
		font-weight:300;
	}

	.disclaimerbox {
		background-color: #eee;
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}

	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}

	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		        15px 15px 0 0px #fff, /* The fourth layer */
		        15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		        20px 20px 0 0px #fff, /* The fifth layer */
		        20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		        25px 25px 0 0px #fff, /* The fifth layer */
		        25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}

	.vert-cent {
		position: relative;
	    top: 50%;
	    transform: translateY(-50%);
	}

	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
	<head>
		<title>SOMSI: Spherical Novel View Synthesis with Soft Occlusion Multi-Sphere Images</title>
		<meta property="og:title" content="SOMSI: Spherical Novel View Synthesis with Soft Occlusion Multi-Sphere Images" />
		<meta property="og:description" content="Habtegebrial et al. 2022" />
  </head>

  <body>
    <br>
          <center>
          	<span style="font-size:36px">SOMSI: Spherical Novel View Synthesis <br> with Soft Occlusion Multi-Sphere Images</span>
	  		  <table align=center width=800px>
	  			  <tr>
	  	              <td align=center width=300px>
	  					<center>
							<span style="font-size:20px"><a href="http://tedyhabtegebrial.github.io/">Tewodros Habtegebrial<sup>1,3</sup> </a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=150px>
	  					<center>
							<span style="font-size:20px"><a href="https://av.dfki.de/members/gava/">Christiano Gava<sup>1,3</sup></a></span>
		  		  		</center>
		  		  	  </td>
						<td align=center width=150px>
							<center>
								<span style="font-size:20px"><a href="https://av.dfki.de/members/rogge/">Marcel Rogge<sup>1,3</sup></a></span>
							</center>
						</td>
					  <td align=center width=150px>
	  					<center>
	  						<span style="font-size:20px"><a href="https://av.dfki.de/members/stricker/">Didier Stricker<sup>1,3</sup></a></span>
		  		  		</center>
		  		  	  </td>
						<td align=center width=150px>
							<center>
								<span style="font-size:20px"><a href="http://varunjampani.github.io/">Varun Jampani<sup>2</sup></a></span>
							</center>
						</td>

						
					</tr>
			  </table>
			<table align="center" width=900>
				<tr align=center>
					<td align=center width=300px> <sup>1</sup> TU Kaiserslautern</td>
					<td align=center width=300px> <sup>2</sup> Google Research</td>
					<td align=center width=300px> <sup>3</sup> DFKI Kaiserslautern</td>
	
				</tr>
			</table>
		  <table align="center" width=850px>
				<center> Accepted at CVPR-2022 </center>
			</table>
          </center>
		  <br>
          <center>
  	<table align=center width=850px>
			<tr>
				<td>
					<!-- <center> -->
					<!-- Describe GVS and out solution.-->
					<!-- </center> -->
				</td>
			</tr>
		</table>
	</center>

          <hr>

<!--   		  <br>
  		  <table align=center width=800px>
  			  <tr>
  	              <td width=400px>
  					<center>
  	                	<a href="./resources/fig1d.jpeg"><img class="" src = "./resources/fig1d.jpeg" height="400px"></img></href></a><br>
					</center>
  	              </td>
                </tr>
  		  </table>
		  <hr> -->

  		  <table align=center width=850px>
	  		  <center><h1>Abstract</h1></center>
	  		  <tr>
	  		  	<td>
							<div align="justify">
							Spherical novel view synthesis (SNVS) is the task of estimating 360
							views at dynamic novel views given a set of 360 input views. Prior arts learn multi-sphere image (MSI)
							representations that enables fast rendering times but are only limited to modelling low-dimensional color values. Modelling high-dimensional appearance features in MSI can result
							in better view synthesis, but it is not feasible to represent high-dimensional
							features in a large number (64) of MSI spheres. We propose a novel MSI representation called Soft Occlusion MSI (SOMSI) that enables modelling high-dimensional appearance features in MSI
							while retaining the fast rendering times of a standard MSI. Our key insight is to model appearance features in a smaller set ($3$)
							of occlusion levels instead of larger number of MSI levels. Experiments on both synthetic and real-world scenes demonstrate that using SOMSI can provide a good balance between accuracy and runtime.
							SOMSI can produce considerably better results compared to MSI based MatryODSHka, while having similar fast rendering time. SOMSI view synthesis quality is on-par with
							state-of-the-art NeRF like model while being 2 orders of magnitude faster.
							</div>
	  		    </td>
	  		  </tr>
			</table>
  		  <br>
		  <hr>

  		  <table align=center width=700px>
	  		  <center><h1>Method overview</h1></center>
  			  <tr>
  	              <td align=center width=700px>
  					<center>
						  <td><img class="round" style="width:800px" src="./resources/approach_overview.png-1.png"/></td>
	  		  		</center>
			  </tr>
		  </center>
		  </table>
  		  <table align=center width=850px>
		  	<center>
		  		<tr>
		  			<td>
				  	<!-- Method overview -->
		  			</td>
		  		</tr>
		  </center>
		  </table>
		  <br>
        <hr>
        <center><h1>Supplementary Video Coming Soon</h1></center>
        <!-- <p align="center">
				<iframe width="660" height="395" src="https://www.youtube.com/embed/qz2yX8TIzDk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen align="center"></iframe></p> -->

<!--   		  <table align=center width=700px>
  			  <tr>
  	              <td align=center width=700px>
  					<center>
						  <td><img class="round" style="width:800px" src="./resources/fig1e.jpg"/></td>
	  		  		</center>
			  </tr>
		  </table>
		  <br> -->

		<!--
		  <hr>

        <center><h1>Supplementary Video</h1></center>
        <p align="center">
		<iframe width="660" height="395" src="https://youtu.be/kyi5W5rKOnw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen align="center"></iframe></p>


  		  <table align=center width=800px>
			  <br>
			  <tr><center>
				<span style="font-size:28px">&nbsp;<a href='https://www.dropbox.com/s/bzo8kia5si811tm/antialiasing_bair.pptx?dl=0'>[Slides]</a>
		  </table>
        <hr>
		-->
	  <!-- NETWORK ARCHITECTURE, TRY THE MODEL -->
	  <!--
 		<center><h1>Code and Antialiased Models</h1></center>

  		  <table align=center width=420px>
		  	<center>
		  		<tr>
		  			<td>
		  				<b>ImageNet Classification (shift-invariance vs accuracy)</b>
		  			</td>
		  		</tr>
		  </center>
		  </table>
  		  <table align=center width=400px>
  			  <tr>
  	              <td align=center width=400px>
  					<center>
						  <td><img class="round" style="width:450px" src="./resources/imagenet_ind2_noalex.jpg"/></td>

	  		  		</center>
			  </tr>
		  </table>

  		  <table align=center width=850px>
		  	<center>
		  		<tr>
		  			<td>
		  	As designed, adding low-pass filtering increases <b>shift-invariance (y-axis)</b>. Surprisingly, we also observe increases in <b>accuracy (x-axis)</b>, across architectures, as well as increased robustness. We have pretrained anti-aliased models, along with instructions for making your favorite architecture more shift-invariant.
		  			</td>
		  		</tr>
		  </center>
		  </table>
		   -->
			<table align=center width=800px>
				<br>
				<tr>
					<center>
						<span style="font-size:28px">&nbsp;<a href='https://drive.google.com/drive/folders/1baI9zZCOJyjI278LCylnHWNF41KI-JkF?usp=sharing'>[Data: click here to download the dataset]</a>
			</table>
		   <table align=center width=800px>
			  <br>
			  <tr><center>
				<span style="font-size:28px">&nbsp;<a href='https://github.com/tedyhabtegebrial/SoftOcclusionMSI'>[Code]</a>
		  </table>

<!-- <a href="http://www.eecs.berkeley.edu/~rich.zhang/projects/2016_colorization/files/demo_v0/colorization_release_v0.caffemodel">[Model 129MB]</span> -->

      	  <br>
		  <hr>

  		  <!-- <table align=center width=550px> -->
  		  <table align=center width=490px>
	 		<center><h1>Paper and Supplementary Material: Coming Soon</h1></center>
			 <!-- <tr>
				  
				  <td><a href="https://arxiv.org/abs/2008.09106"><img class="layered-paper-big" style="height:175px" src="./resources/paper.png"/></a></td>
				  <td><span style="font-size:14pt">Tewodros Habtegebrial, Varun Jampani, Orazio Gallo, Didier Stricker.<br>
				  <b>Generative View Synthesis: <em>From Single-view Semantics to Novel-view Images  </em></b><br>
				  Arxiv Preprint, 2020. <a href="https://arxiv.org/abs/2008.09106">Link</a><br>
				  <span style="font-size:4pt"><a href=""><br></a>
				  </span>
				  </td>
  	              </td>
              </tr> -->
  		  </table>
		  <br>

		  <!-- <table align=center width=600px>
			  <tr>
				  <td><span style="font-size:14pt"><center>
				  	<a href="./resources/arxiv_bib.txt">[Bibtex]</a>
  	              </center></td>
              </tr>
  		  </table> -->

		  <hr>
		  <br>

<!-- <table align=center width=900px>
	<tr> <td> <span style="font-size:14pt"> References<center> </td> </tr>
	<tr> <td> [1] SPADE: <em>Semantic Image Synthesis with Spatially-Adaptive Normalization</em>, Park et al. <a href="https://arxiv.org/abs/1903.07291">link</a></td> </tr>
	<tr> <td> [2] SM: <em> Stereo Magnification: Learning View Synthesis using Multiplane Images</em>, Zhou et al. <a href="https://people.eecs.berkeley.edu/~tinghuiz/projects/mpi/"> link </a> </td> </tr>
	<tr> <td> [3] CVS: <em> Monocular Neural Image Based Rendering with Continuous View Control</em>, Chen et al.   <a href="https://arxiv.org/abs/1901.01880">link</a></td> </tr>

</table> -->
<hr>
<br>
  		  <table align=center width=900px>
  			  <tr>
  	              <td width=400px>
  					<left>
				Acknowledgements: Coming Soon

			</left>
		</td>
			 </tr>
		</table>

		<br>


</body>
</html>
